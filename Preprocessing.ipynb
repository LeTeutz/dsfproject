{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda8f2e",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "You might get a `DtypeWarning`; ignore it now, if necessary, deal with it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dadd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the raw dataset\n",
    "df = pd.read_csv('LendingClub_wi3435TU.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6339722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6438e5f",
   "metadata": {},
   "source": [
    "#### Loading the data dictionary\n",
    "The field descriptions are read in as a Pandas data frame and then extended to a (Pandas) data frame `preview` for a first peek at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f28b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 1200) # controls output width; might need adjustment\n",
    "data_dictionary = pd.read_csv('LCDataDictionary.csv') # Loading in the data dictionary\n",
    "data_dictionary = data_dictionary.rename(columns={'LoanStatNew': 'name', 'Description': 'description'})\n",
    "data_dictionary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6848616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate preview names + dtypes + first values + descriptions\n",
    "df_dtypes = pd.DataFrame(df.dtypes,columns=['dtypes'])\n",
    "df_dtypes = df_dtypes.reset_index()\n",
    "df_dtypes['name'] = df_dtypes['index']\n",
    "df_dtypes = df_dtypes[['name','dtypes']]\n",
    "df_dtypes['first value'] = df.loc[0].values\n",
    "preview = df_dtypes.merge(data_dictionary, on='name',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d3d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview[35:47]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79858351",
   "metadata": {},
   "source": [
    "## Features with a lot of missing values\n",
    "A global investigation into the missing values, using `plt.hist` from Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780d4b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall fraction of null values in the data\n",
    "(df.isnull().sum().sum())/(df.shape[0]*df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd9049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create overview of distribution of NAs over the variables:\n",
    "nullfrac= df.isnull().sum()/df.shape[0]\n",
    "plt.hist(nullfrac,bins=20)\n",
    "print(\"Number of fields with more than 10% NAs:\", sum(nullfrac>0.10))\n",
    "print(\"Number of fields with less than 1%% NAs:\", sum(nullfrac<0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b86e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to drop the feature from a list\n",
    "drop_list = ['member_id']\n",
    "df.drop(drop_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b34c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10db34c7",
   "metadata": {},
   "source": [
    "## Filtering on loan_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd74a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4951ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value counts, this time fancy in a Pandas data frame\n",
    "meaning = [\n",
    "\"Loan has been fully paid off.\",\n",
    "\"Loan is up to date on current payments.\",\n",
    "\"Loan for which there is no longer a reasonable expectation of further payments.\",\n",
    "\"Loan hasn't been paid in 31 to 120 days (late on the current payment).\",\n",
    "\"The loan is past due but still in the grace period of 15 days.\",\n",
    "\"Loan hasn't been paid in 16 to 30 days (late on the current payment).\",\n",
    "\"Loan is defaulted on and no payment has been made for more than 121 days.\"]\n",
    "status, count = df[\"loan_status\"].value_counts().index, df[\"loan_status\"].value_counts().values\n",
    "loan_statuses_explanation = pd.DataFrame({'Loan Status': status,'Count': count,'Meaning': meaning})[['Loan Status','Count','Meaning']]\n",
    "loan_statuses_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2492a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how you might do this. Complete?\n",
    "df = df[(df[\"loan_status\"] == \"Fully Paid\") | (df[\"loan_status\"] == \"Charged Off\")]\n",
    "mapping_dictionary = {\"loan_status\":{ \"Fully Paid\": 1, \"Charged Off\": 0, \"Default\": 0}}\n",
    "df = df.replace(mapping_dictionary)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18b6406",
   "metadata": {},
   "source": [
    "## Preventing leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c1fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect list of features that are not available at the application date\n",
    "drop_list1 = []\n",
    "df.drop(drop_list1, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dde58f",
   "metadata": {},
   "source": [
    "## Dropping features of no/little predictive value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917bdbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCOMPLETE\n",
    "drop_list2 = ['id','disbursement_method']\n",
    "df.drop(drop_list2, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f944c076",
   "metadata": {},
   "source": [
    "## Unbalanced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6ab261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of how to look at some value-counts\n",
    "for col in df.columns[26:31]:\n",
    "    print(df[col].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648109e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "drop_list3 = ['initial_list_status']\n",
    "df.drop(drop_list3, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008124eb",
   "metadata": {},
   "source": [
    "## Highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e657bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking correlation and using heatmap to visualise it.\n",
    "# First select a subset of the columns to keep the size of the correlation matrix low\n",
    "# Output looks a bit strange, is it OK?\n",
    "select = list(df.columns[45:65])     \n",
    "dfsel = df[select]\n",
    "sns.set(rc={'figure.figsize':(20,20)})\n",
    "sns.set_style('whitegrid')\n",
    "# Compute correlations and plot heatmap (exclude non-numeric features)\n",
    "correlations = dfsel.corr(numeric_only=True)\n",
    "sns.heatmap(correlations,annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cce3d9",
   "metadata": {},
   "source": [
    "## Getting rid of the remaining missing values\n",
    "Upon first running, before (many) features have been dropped, the list below might/will still contain a large number of feature, many with a large number of missing values. This might indicate you have not cleaned enough in the earlier stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54697b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f9a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe of null-counts and look at the numbers\n",
    "# This only makes sense when you have done most of the other cleaning\n",
    "NAcount= df.isnull().sum()\n",
    "hasNAs = NAcount[NAcount>0]\n",
    "print(\"There are\", len(hasNAs), \"features that have missing values.\")\n",
    "b = pd.DataFrame(hasNAs,columns=['Number of null values'])\n",
    "b.sort_values(by=['Number of null values'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # check dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b4ac1e",
   "metadata": {},
   "source": [
    "## Dates\n",
    "There may or may not be any date features left. Let's check the categorical features still present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5faebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data types and their frequency\\n{}\".format(df.dtypes.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cf7596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list of remaining categorical features\n",
    "# obcols = list(df.columns[df.dtypes == 'object'])\n",
    "# obcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003face",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in obcols:\n",
    "#    print(preview[preview.name == col][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9abd232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is crummy code ... sorry\n",
    "pd.set_option('max_colwidth', 20)\n",
    "object_columns_df = df.select_dtypes(include=['object'])\n",
    "print(object_columns_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f56d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
